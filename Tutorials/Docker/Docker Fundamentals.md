

# Kernel in OS:

The **kernel** of an operating system is its **core component** ‚Äî the part that **directly interacts with the hardware** and manages all low-level tasks.

---
## üîß In simple terms:

> **The kernel is the brain of the OS.**  
> It controls how software talks to hardware.

---
## üß† What the Kernel Does:

1. **Memory Management**  
    Allocates and tracks RAM used by programs  
    ‚Üí Prevents apps from corrupting each other‚Äôs memory
    
2. **Process Management**  
    Starts/stops programs, schedules CPU time  
    ‚Üí Ensures fair and efficient execution of multiple apps
    
3. **Device Management**  
    Talks to hardware via drivers (keyboard, disk, GPU, etc.)  
    ‚Üí Provides a uniform way for software to access devices
    
4. **File System Management**  
    Reads/writes data to storage devices  
    ‚Üí Handles permissions, paths, and file operations
    
5. **System Call Interface**  
    Acts as the **bridge between user apps and hardware**  
    ‚Üí Apps use "system calls" to ask the kernel to do things
    
---
## üì¶ Types of Kernels:

| Type            | Description                                                               |
| --------------- | ------------------------------------------------------------------------- |
| **Monolithic**  | All OS services run in kernel space (e.g., Linux)                         |
| **Microkernel** | Minimal kernel, with most services in user space (e.g., Minix, QNX)       |
| **Hybrid**      | Combines monolithic + microkernel traits (e.g., Windows NT, macOS kernel) |

---
## üìç Example: In Linux
- The **Linux kernel** is the `.tar.xz` blob maintained by Linus Torvalds and others.
- Ubuntu, Fedora, Arch etc. are just **distros** = kernel + userland tools.
---
## üí° Analogy

Imagine a computer is a car:
- **Hardware** = Engine, brakes, steering
- **Applications** = The driver
- **Kernel** = The car‚Äôs onboard computer controlling everything  
    (Driver says ‚Äúbrake‚Äù ‚Üí kernel signals brakes to engage)
---
If you're a programmer or working with systems, the kernel is the layer that gives your code safe, abstract access to hardware.

# Virtual Machines (VMs)

A **virtual machine (VM)** is a software-defined computer that emulates the functions of a physical computer. Each VM has its own:

- **Virtual Hardware:** This includes a virtual CPU, virtual memory, virtual hard disk, and virtual network interfaces.
    
- **Guest Operating System (OS):** This is the operating system installed within the VM (e.g., Windows, Linux, macOS), completely isolated from the host OS.
    
- **Applications:** Software applications run within the guest OS, just as they would on a physical machine.    

From the perspective of the guest OS and the applications running inside it, a VM behaves exactly like a standalone physical machine.

# Hypervisors and virtual machines:

A **hypervisor** is a specialized **software layer (or firmware)** that allows **multiple virtual machines (VMs)** to run on a single physical machine by **abstracting and managing the underlying hardware resources.**

The term "hypervisor" is derived from "supervisor," which is a traditional term for the kernel of an operating system. The "hyper-" prefix suggests that it's a "supervisor of supervisors," as it manages multiple operating system kernels within different VMs.

Think of a hypervisor as a **virtual hardware manager** or as a traffic controller or a manager for your computer's hardware resources. Before hypervisors, a physical computer could only run one operating system at a time. This often led to underutilization of powerful server hardware. The hypervisor solves this by abstracting the physical hardware and allowing multiple operating systems to share those resources efficiently.

![[Pasted image 20250719111619.png]]
### How Hypervisors are Used in Virtual Machines

The hypervisor's primary role is to create, manage, and isolate Virtual Machines (VMs) on a physical host. Here's how it works in detail:

1. **Hardware Abstraction:** The hypervisor creates a layer of abstraction between the physical hardware and the VMs. It effectively hides the complexities of the underlying physical components (CPU, memory, storage, network interfaces) and presents a standardized, virtual set of hardware to each VM. This means that a VM doesn't "know" it's running on virtualized hardware; it believes it has its own dedicated physical components. This abstraction is crucial for portability, as a VM can be moved between different physical hosts without compatibility issues.
    
2. **Resource Allocation and Management:**
    
    - **CPU:** The hypervisor schedules CPU time for each VM. When a VM needs to execute instructions, the hypervisor allocates a slice of the physical CPU's time to that VM. It manages the context switching between different VMs, ensuring that each VM gets its fair share of processing power and that one VM doesn't monopolize the CPU.
        
    - **Memory:** The hypervisor manages the physical RAM and allocates portions of it to each VM. It uses techniques like "memory ballooning" (where a driver inside the guest OS can reclaim unused memory from the VM) and "page sharing" (where identical memory pages across different VMs are stored only once) to optimize memory usage.
        
    - **Storage:** The hypervisor virtualizes the physical storage. VMs typically see virtual hard disks, which are essentially large files on the host's physical storage. The hypervisor handles all read/write requests from the VMs to the actual physical disks.
        
    - **Networking:** The hypervisor creates virtual network interfaces for each VM and connects them to virtual switches. These virtual switches then connect to the host's physical network adapters, allowing VMs to communicate with each other and with external networks.
        
3. **Isolation:** This is a critical function of the hypervisor. Each VM is isolated from other VMs and from the host machine. If one VM crashes, is infected with malware, or experiences a software bug, it generally does not affect other VMs or the integrity of the host system. The hypervisor enforces this separation by controlling access to shared resources and preventing direct communication or interference between VMs without explicit configuration. This isolation enhances security and stability.
    
4. **Emulation and Virtualization:**
    
    - For some hardware components, the hypervisor might fully **emulate** the hardware in software. This means it creates a software representation of the hardware that the VM interacts with, even if the underlying physical hardware is different.
        
    - For performance-critical components like the CPU, modern hypervisors often leverage **hardware-assisted virtualization** features (e.g., Intel VT-x, AMD-V). These features, built into the CPU, provide special instructions that allow the hypervisor to run guest OS instructions directly on the physical CPU without much overhead, significantly improving performance.
        
5. **VM Lifecycle Management:** The hypervisor provides tools and mechanisms for:
    
    - **Creating VMs:** Defining virtual hardware specifications (CPU cores, RAM, disk space) for a new VM.
    - **Starting/Stopping VMs:** Powering on and off virtual machines.
    - **Pausing/Resuming VMs:** Suspending a VM's operation and resuming it later.
    - **Cloning VMs:** Creating exact copies of existing VMs.
    - **Snapshots:** Capturing the entire state of a VM at a specific point in time, allowing for easy rollback.
    - **Migration (Live Migration/vMotion):** Moving a running VM from one physical host to another without downtime

### Types of Hypervisors

There are two main types:

1. **Type 1 Hypervisor (Bare-metal or Native Hypervisor):**
    
    - **Placement:** Installs directly on the physical hardware, without an underlying host operating system. It essentially _is_ the operating system for the physical server, designed specifically for virtualization.
        
    - **Characteristics:**
        
        - **High Performance:** Direct access to hardware leads to minimal overhead and excellent performance.
        - **High Security:** Smaller attack surface as there's no general-purpose host OS.
        - **Enterprise-grade:** Commonly used in data centers and cloud computing environments for mission-critical workloads.
            
    - **Examples:** VMware ESXi, Microsoft Hyper-V, Citrix Hypervisor (formerly XenServer), KVM (Kernel-based Virtual Machine - integrated into Linux kernel).
        
2. **Type 2 Hypervisor (Hosted Hypervisor):**
    
    - **Placement:** Runs as an application on top of a conventional host operating system (e.g., Windows, macOS, Linux).
        
    - **Characteristics:**
        
        - **Easier Setup:** Simpler to install and use, as it's just another application.            
        - **Convenient for Desktops:** Popular for individual users or developers who need to run multiple operating systems on their personal computers.
        - **Lower Performance (generally):** Performance can be slightly lower due to the overhead of the host OS, which adds an extra layer between the VM and the hardware.
        - **Less Isolation:** While VMs are still isolated from each other, a compromise of the host OS could potentially affect the VMs.
            
    - **Examples:** Oracle VirtualBox, VMware Workstation, Parallels Desktop.
#### In Cloud/Enterprise

- **Cloud providers** (AWS, Azure, GCP) use Type 1 hypervisors at massive scale
- Each EC2 instance on AWS is a **VM managed by a hypervisor** like KVM or Xen
- Hypervisors allow:
    - Multi-tenancy (different users on same hardware)
    - Efficient resource utilization
    - Strong isolation for security

# What are Containers?

A **container** is a lightweight, executable package of software that includes everything needed to run a piece of software: the application code, a runtime (like Python, Node.js, Java JVM), system libraries, system tools, and configuration files. It's designed to ensure that the application runs quickly and reliably from one computing environment to another, regardless of differences in the underlying operating system.

**Key characteristics of containers:**

- **Operating System (OS) Level Virtualization:** Unlike VMs, containers do not include an entire operating system. Instead, they share the **host operating system's kernel**. This is the fundamental difference.
    
- **Lightweight:** Because they share the host OS kernel and only package the application and its dependencies, containers are significantly smaller (typically tens to hundreds of megabytes) and consume fewer resources (CPU, memory) compared to VMs.
    
- **Fast Startup:** Without the need to boot an entire operating system, containers can start up in seconds, even milliseconds.
    
- **Portability:** A container image is a self-contained unit that can be moved and run consistently across any environment that has a compatible container engine (like Docker) and the necessary host OS kernel. This "build once, run anywhere" philosophy is a core benefit.
    
- **Isolation:** Containers provide process-level isolation. Each container has its own isolated filesystem, network interfaces, and process space, making it appear as if it's running on its own dedicated machine. This prevents conflicts between applications and ensures consistency.
    
- **Container Engine:** A "container engine" or "container runtime" (e.g., Docker, containerd, Podman) is the software responsible for building, running, and managing containers on the host. It leverages features of the host OS kernel like **namespaces** (for isolation of process trees, network interfaces, mount points, etc.) and **control groups (cgroups)** (for resource allocation and limiting CPU, memory, I/O).

## How Containers Work:

1. **Container Engine**: Uses a container runtime (like Docker, containerd, or Podman)
2. **Shared Kernel**: All containers share the host OS kernel
3. **Process Isolation**: Uses OS-level features (namespaces, cgroups) for isolation
4. **Layered Filesystem**: Uses union filesystems for efficient storage

### Container Architecture:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      App 1    ‚îÇ    App 2    ‚îÇ   App 3   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ   Container 1 ‚îÇ Container 2 ‚îÇContainer 3‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ           Container Engine              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ         Host Operating System           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ           Physical Hardware             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

Notice that the command-line interface, or CLI, runs in what is called user space
memory just like other programs that run on top of the operating system. Ideally, programs running in user space can‚Äôt modify kernel space memory. Broadly speaking, the operating system is the interface between all user programs and the hardware that the computer is running on.
![[Pasted image 20250719114345.png]]

### The Docker Engine: Client, Daemon, and REST API

  The Docker Engine is the core component that builds and runs Docker containers. It comprises three main elements:

- Docker Client: This is the primary way users interact with Docker. It is a command-line interface (CLI) tool that sends commands to the Docker Daemon. For instance, when a user types docker run, the Docker Client translates this into an API request and sends it to the Docker Daemon. This separation of concerns allows for flexible interaction, including remote management.
    
- Docker Daemon (dockerd): Often referred to as dockerd, this background service runs on the host machine. It is responsible for building, running, and distributing Docker containers. The daemon listens for API requests from the Docker Client and manages Docker objects such as images, containers, volumes, and networks. The daemon acts as the orchestrator, handling all the heavy lifting of container lifecycle management.
    
- REST API: The Docker Daemon exposes a RESTful API that the Docker Client uses to communicate with it. This API defines the interfaces that programs can use to talk to the daemon and instruct it to perform actions. The existence of a well-defined API means that not only the Docker CLI but also other tools and platforms can programmatically interact with Docker, enabling powerful integrations and automation. This API-driven approach is fundamental to Docker's extensibility and its role in broader orchestration ecosystems.
    
You can see in figure 1.2 that running Docker means running two programs in user space. The first is the Docker daemon. If installed properly, this process should always be running. The second is the Docker CLI. This is the Docker program that users interact with. If you want to start, stop, or install software, you‚Äôll issue a command using the Docker program.
![[Pasted image 20250719115114.png]]

Figure 1.2 also shows three running containers. Each is running as a child process
of the Docker daemon, wrapped with a container, and the delegate process is running
in its own memory subspace of the user space. Programs running inside a container
can access only their own memory and resources as scoped by the container. The containers that Docker builds are isolated with respect to eight aspects. The specific aspects are as follows:
### Linux Namespaces: Isolation at the OS Level

  Linux Namespaces provide isolated views of global system resources. Each namespace creates a distinct environment, making processes within one namespace unaware of processes or resources in other namespaces. Docker leverages several types of namespaces to create the isolated environment of a container:

- PID Namespace (Process ID): **Isolates the process tree**. A process running inside a container will have its own PID 1, appearing as the init process within that container, even though it's not PID 1 on the host system. This isolation means that processes within a container cannot see or interact with processes outside their namespace, enhancing security and preventing unintended interference.
    
- NET Namespace (Network): **Provides an isolated network stack**, including network interfaces, IP addresses, routing tables, and port numbers. Each container gets its own network interface, making it appear as if it has its own dedicated network setup. This enables multiple containers to run on the same host without IP address or port conflicts, which is crucial for running multiple instances of the same service.
    
- MNT Namespace (Mount): **Isolates the filesystem mount points**. Processes in different mount namespaces can have different views of the filesystem hierarchy. This allows each container to have its own root filesystem, independent of the host's or other containers', ensuring that dependencies and configurations are self-contained.
    
- UTS Namespace (UNIX Timesharing System): **Isolates hostname and NIS domain name**. A container can have its own hostname, which is distinct from the host's hostname. This contributes to the illusion that a container is a separate machine.
    
- IPC Namespace (Inter-Process Communication): Isolates IPC resources like System V IPC and POSIX message queues. This prevents processes in one container from interfering with IPC mechanisms in another.

- USER Namespace (User ID): Isolates user and group IDs. This allows a user inside a container to have root privileges within that container's namespace, while being mapped to a non-privileged user on the host system, significantly enhancing security. This mapping is a powerful security feature, as a compromise within the container does not automatically grant root access on the host.**
### Linux Control Groups (cgroups): Resource Management  

While namespaces provide isolation, Control Groups (cgroups) are responsible for resource allocation and limiting. Cgroups allow the Docker Daemon to manage and restrict the resources (CPU, memory, I/O, network bandwidth) that each container can consume.

- Resource Limiting: Cgroups prevent a single container from monopolizing host resources, ensuring fair distribution among multiple containers and the host system itself. For example, a container can be limited to a specific amount of CPU time or memory, preventing resource exhaustion issues.
    
- Prioritization: Resources can be prioritized, ensuring critical containers receive more resources during contention.
    
- Accounting: Cgroups track resource usage, providing metrics that can be used for monitoring and billing.
    
**The combination of namespaces for isolation and cgroups for resource management forms the backbone of Docker's lightweight virtualization.** This dual mechanism allows containers to run efficiently, sharing the host kernel while maintaining strong boundaries between applications.

### How Docker Leverages These Primitives

Docker orchestrates these Linux kernel features to create and manage containers. When a docker run command is executed, the Docker Daemon:

1. Creates Namespaces: It creates a new set of namespaces (PID, NET, MNT, UTS, IPC, USER) for the new container, giving it an isolated view of the system.
    
2. Configures Cgroups: It sets up cgroups for the container, defining its resource limits and priorities based on the Docker run command options (e.g., --memory, --cpus).
    
3. Mounts Filesystem: It mounts the image's layered filesystem into the container's mount namespace, along with a writable layer for runtime changes.
    
4. Starts Process: It executes the container's entry point command within this isolated and resource-constrained environment.
    
This deep reliance on native Linux kernel features explains why Docker containers are so efficient compared to virtual machines, as they avoid the overhead of a separate guest operating system. The ability to directly leverage the host kernel's capabilities means that containers can achieve near-native performance, which is a significant advantage for high-performance applications.

### How are Containers Different from Virtual Machines?

Here's a detailed comparison highlighting the key differences:

| Feature                    | Virtual Machine (VM)                                                                                                                                                                                                                                                                                                                                       | Container                                                                                                                                                                                                                                                                                                                                                            |
| -------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Virtualization Level**   | **Hardware Virtualization:** VMs virtualize the entire hardware stack (CPU, memory, storage, network). They run on a **hypervisor** (Type 1 or Type 2).                                                                                                                                                                                                    | **Operating System Level Virtualization:** Containers virtualize the OS. They run on a **container engine** (e.g., Docker) which runs on top of the host OS kernel.                                                                                                                                                                                                  |
| **Operating System**       | Each VM includes its **own full guest operating system** (OS kernel + user space), completely independent of the host OS and other VMs.                                                                                                                                                                                                                    | Containers **share the host operating system's kernel**. They only package the application and its necessary libraries and dependencies (user space).                                                                                                                                                                                                                |
| **Resource Usage**         | **Resource-intensive:** Each VM requires a full OS, consuming significant CPU, memory, and storage (typically **gigabytes**). This leads to higher overhead.                                                                                                                                                                                               | **Lightweight:** Shares the host OS kernel, so containers only package the application and its dependencies. This makes them much smaller (typically **megabytes**) and more resource-efficient.                                                                                                                                                                     |
| **Startup Time**           | **Slower:** Requires booting a full OS, which can take minutes.                                                                                                                                                                                                                                                                                            | **Faster:** Starts in seconds (or even milliseconds) as it only needs to start the application process, not a full OS.                                                                                                                                                                                                                                               |
| **Isolation Level**        | **High Isolation:** Provides strong isolation at the hardware level. Each VM is completely isolated from other VMs and the host machine, including its own kernel. A problem in one VM typically doesn't affect others.                                                                                                                                    | **Lower Isolation:** Provides process isolation. While containers are isolated from each other in terms of processes and file systems, they share the host OS kernel. A security vulnerability in the host kernel could potentially affect all containers running on it.                                                                                             |
| **Portability**            | **Highly portable:** A VM image (a single file) can be moved between different hypervisor-compatible hosts, even if the underlying physical hardware differs, because the VM brings its own OS.                                                                                                                                                            | **Highly portable:** Container images are designed to run consistently across any environment with a compatible container runtime and host OS kernel. This is their strong suit for "build once, run anywhere."                                                                                                                                                      |
| **Guest OS Compatibility** | Can run **different guest OSes** than the host OS (e.g., run Windows VMs on a Linux host, or Linux VMs on a Windows host).                                                                                                                                                                                                                                 | Typically runs applications designed for the **same OS kernel as the host** (e.g., Linux containers on a Linux host). While tools like Docker Desktop allow running Linux containers on Windows/macOS, they often achieve this by running a lightweight Linux VM under the hood.                                                                                     |
| **Typical Use Cases**      | - Running legacy applications requiring specific OS versions.  <br>- Running multiple different OSes on one physical machine.  <br>- Providing strong isolation for security-critical workloads.  <br>- Testing environments where full OS control is needed.  <br>- Fundamental building block for Infrastructure as a Service (IaaS) in cloud computing. | - Microservices architecture (breaking down large applications into smaller, independent services).  <br>- Rapid application deployment and scaling.  <br>- DevOps and CI/CD pipelines (ensuring consistent environments from development to production).  <br>- Packaging and running single applications or services.  <br>- Cloud-native application development. |
| **Management**             | Managed by the hypervisor and traditional OS management tools.<br><br>                                                                                                                                                                                                                                                                                     | Managed by container orchestration platforms like Kubernetes, Docker Swarm, Nomad.                                                                                                                                                                                                                                                                                   |

### What is a Docker Image? 

A Docker image is a **lightweight, standalone, executable package** that includes everything needed to run a piece of software, including:

1. **Application Code:** Your actual software application (e.g., a Python script, a Java JAR file, a Node.js server).
    
2. **Runtime:** The environment required to execute your code (e.g., Python interpreter, Node.js runtime, Java Virtual Machine (JVM)).
    
3. **System Tools & Libraries:** Any operating system tools (like `apt-get`, `yum`, `grep`) and libraries (like `glibc`, `libssl`) that your application or its runtime depends on.
    
4. **Dependencies:** Any third-party libraries or packages that your application needs.
    
5. **Configuration Files:** Settings, environment variables, and other configuration data required for the application to function correctly.
    
Essentially, a Docker image is a **snapshot** of a complete, ready-to-run environment. It's a read-only template from which Docker containers are created.

**Key characteristics of a Docker Image:**

- **Immutable:** Once built, a Docker image cannot be changed. If you need to make modifications, you create a _new_ image. This immutability ensures consistency across different environments.
    
- **Versioned:** Docker images can be tagged with versions (e.g., `myapp:1.0`, `myapp:latest`), allowing you to manage different releases of your application.
    
- **Shareable:** Images can be pushed to and pulled from **Docker registries** (like Docker Hub, GitLab Container Registry, Google Container Registry), making it easy to share applications with teams or deploy them to production.
    
- **Portable:** Because an image contains everything needed, it can be run consistently on any machine with a Docker engine, regardless of the host OS's specific configurations (as long as the underlying kernel is compatible, typically Linux).

## How is a Docker Image Used to Create a Container?

The relationship between a Docker image and a Docker container is analogous to the relationship between a class and an object in object-oriented programming, or a blueprint and a house.

1. **Image as a Blueprint:** The Docker image acts as a read-only blueprint or template. It defines the entire environment and application.
    
2. **Container as an Instance:** When you run a Docker image, the Docker engine creates a **container**, which is a _runnable instance_ of that image.
    
    The process typically involves:
    
    - **`docker run <image_name>`:** This is the primary command used.
        
    - **Docker Engine's Actions:**
        
        - **Pulls the Image (if not local):** If the image isn't already on your local machine, the Docker engine will pull it from a configured Docker registry (like Docker Hub).
        
        - **Creates a Writable Layer:** On top of the image's read-only layers (explained below), the Docker engine adds a new, thin, writable layer. This is where all changes made by the running container (e.g., new files, modified files, logs) are stored.    
        
        - **Mounts Filesystem:** It mounts the image's layered filesystem into the container's mount namespace
            
        - **Creates Namespaces:** It creates a new set of namespaces (PID, NET, MNT, UTS, IPC, USER) for the new container, giving it an isolated view of the system.
        
        - **Configures Cgroups:** It sets up cgroups for the container, defining its resource limits and priorities based on the Docker run command options (e.g., --memory, --cpus).
        
        - **Starts the Process:** It then starts the primary process defined in the image (e.g., your application's `main` function or entry point) within this isolated environment.
            
**In simpler terms:** You download a complete application package (the image), and then Docker uses that package to create an isolated, running instance of your application (the container). Multiple containers can be run from the same image, and each container will be isolated from the others.

### Concept of Layered Filesystems (Union File System) in Docker Images

This is where the magic of Docker's efficiency and speed comes into play. Docker images are built using a **layered filesystem architecture**, often implemented with technologies like **Union File Systems** (e.g., OverlayFS, AUFS, Btrfs).

#### What are Layers in a Docker Image?

A Docker image is not a single, monolithic file. Instead, it's composed of a series of **read-only layers**, stacked one on top of the other. Each layer represents a specific instruction in the `Dockerfile` (the script used to build an image).

Let's illustrate with a simple `Dockerfile`:

```Dockerfile
# Layer 1: Base Image
FROM ubuntu:latest
# Layer 2: Install a package
RUN apt-get update && apt-get install -y curl
# Layer 3: Add application code
COPY . /app
# Layer 4: Set working directory
WORKDIR /app
# Layer 5: Define the command to run
CMD ["python3", "app.py"]
```

When this `Dockerfile` is built, Docker performs the following:

1. **`FROM ubuntu:latest`**: Creates the first layer, containing the base Ubuntu operating system files.
2. **`RUN apt-get update && apt-get install -y curl`**: Creates a new layer on top of the Ubuntu layer. This new layer contains only the _changes_ made by installing `curl` (new files, modified configuration).
3. **`COPY . /app`**: Creates another layer on top, containing your application files copied into the image.
4. **`WORKDIR /app`**: This instruction might not create a new filesystem layer, but rather modify metadata about the subsequent layers.
5. **`CMD ["python3", "app.py"]`**: This instruction primarily defines the default command to run when the container starts and doesn't typically create a new filesystem layer.
    
Each `RUN`, `COPY`, `ADD`, and some `VOLUME` instructions in a `Dockerfile` typically result in a new read-only layer being added to the image.

### How Union File System Works

A Union File System (like OverlayFS, which is commonly used by Docker on Linux) works by **overlaying** multiple distinct filesystems (the image layers) on top of each other to create a single, unified view.

Here's how it operates:

1. **Stacking Layers:** All the read-only layers of a Docker image are stacked.    
2. **Unified View:** The Union File System presents these layers as one cohesive filesystem to the container.    
3. **"Copy-on-Write" Mechanism:** This is the most critical concept. When a container is launched from an image:
    - Docker adds a new, thin, **writable layer** on top of the read-only image layers. This is often called the "container layer" or "top layer."        
    - Any changes made by the running container (e.g., creating a new file, modifying an existing file, deleting a file) are written _only_ to this writable top layer.
    - If a file exists in a lower, read-only layer and the container modifies it, the Union File System doesn't modify the original file in the lower layer. Instead, it copies the file from the lower layer to the writable top layer, and then the modifications are applied to this copied version. This is the "copy-on-write" principle. Subsequent reads of that file will then access the modified version in the top layer.        
    - If a file is deleted from the container, a "whiteout" file is created in the writable layer, effectively hiding the file from the lower layers without actually deleting it from the underlying image.

#### Benefits of Layered Filesystems / Union File Systems:

- **Efficiency:**
    - **Storage:** Docker images are incredibly efficient with storage. If multiple images share common base layers (e.g., many images built `FROM ubuntu`), those common layers are stored only once on disk.        
    - **Bandwidth:** When pulling an image from a registry, only the layers you don't already have locally need to be downloaded, saving bandwidth.
        
- **Speed:**
    - **Image Building:** During image builds, Docker caches layers. If an instruction in the `Dockerfile` hasn't changed since the last build, Docker reuses the existing layer, speeding up the build process.        
    - **Container Creation:** Creating a new container from an image is very fast because Docker only needs to create a new writable layer and set up the isolation mechanisms; it doesn't need to duplicate the entire image filesystem.
        
- **Immutability and Consistency:** Each layer is read-only, ensuring that changes in one container don't affect the original image or other containers derived from the same image. This promotes consistent deployments.
    
- **Version Control:** Layers effectively provide a form of version control for your application's environment. Each instruction in a `Dockerfile` commits a new change to the image, much like Git commits.